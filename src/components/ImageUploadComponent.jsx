import React, { useState, useRef } from 'react';
import { Upload, Image, Camera, FileText, Loader2, Trash2, Download, Eye } from 'lucide-react';

const ImageUploadComponent = ({ selectedModel, onSendMessage }) => {
  const [uploadedImages, setUploadedImages] = useState([]);
  const [isUploading, setIsUploading] = useState(false);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [dragActive, setDragActive] = useState(false);
  const fileInputRef = useRef(null);

  const handleDrag = (e) => {
    e.preventDefault();
    e.stopPropagation();
    if (e.type === "dragenter" || e.type === "dragover") {
      setDragActive(true);
    } else if (e.type === "dragleave") {
      setDragActive(false);
    }
  };

  const handleDrop = (e) => {
    e.preventDefault();
    e.stopPropagation();
    setDragActive(false);
    
    const files = [...e.dataTransfer.files];
    handleFiles(files);
  };

  const handleFileSelect = (e) => {
    const files = [...e.target.files];
    handleFiles(files);
  };

  const handleFiles = async (files) => {
    const imageFiles = files.filter(file => file.type.startsWith('image/'));
    
    if (imageFiles.length === 0) {
      alert('Vui l√≤ng ch·ªçn file ·∫£nh (JPG, PNG, GIF, WebP)');
      return;
    }

    setIsUploading(true);
    
    for (const file of imageFiles) {
      try {
        // Create preview URL
        const previewUrl = URL.createObjectURL(file);
        
        // Convert file to base64 for AI analysis
        const base64 = await fileToBase64(file);
        
        // Upload to Puter cloud for storage
        const uploadedFile = await window.puter.fs.upload([file]);
        
        console.log('Upload response:', uploadedFile); // Debug
        
        // Get the file path from Puter response
        let filePath = '';
        if (Array.isArray(uploadedFile) && uploadedFile.length > 0) {
          filePath = uploadedFile[0].path || uploadedFile[0].name;
        } else if (uploadedFile.path) {
          filePath = uploadedFile.path;
        } else {
          filePath = uploadedFile.name || file.name;
        }
        
        const imageData = {
          id: Date.now() + Math.random(),
          name: file.name,
          size: file.size,
          type: file.type,
          previewUrl: previewUrl,
          filePath: filePath,
          base64: base64, // For AI analysis
          uploadedFile: uploadedFile, // Store full response
          uploadedAt: new Date()
        };
        
        setUploadedImages(prev => [...prev, imageData]);
      } catch (error) {
        console.error('L·ªói upload ·∫£nh:', error);
        alert(`L·ªói upload ${file.name}: ${error.message}`);
      }
    }
    
    setIsUploading(false);
  };

  // Helper function to convert file to base64
  const fileToBase64 = (file) => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.readAsDataURL(file);
      reader.onload = () => resolve(reader.result);
      reader.onerror = error => reject(error);
    });
  };

  const analyzeImage = async (imageData, prompt = "H√£y m√¥ t·∫£ chi ti·∫øt nh·ªØng g√¨ b·∫°n th·∫•y trong ·∫£nh n√†y") => {
    setIsAnalyzing(true);
    
    try {
      const analysisPrompt = `${prompt}\n\n[Ph√¢n t√≠ch ·∫£nh: ${imageData.name}]`;
      
      console.log('Analyzing image with base64...'); // Debug
      
      // Use base64 data for AI analysis (more reliable)
      const response = await window.puter.ai.chat(analysisPrompt, imageData.base64, {
        model: selectedModel
      });
      
      // Process response
      let aiResponseText = '';
      if (typeof response === 'string') {
        aiResponseText = response;
      } else if (response && response.message && response.message.content) {
        if (Array.isArray(response.message.content)) {
          aiResponseText = response.message.content[0]?.text || response.message.content[0];
        } else {
          aiResponseText = response.message.content;
        }
      } else if (response && response.content) {
        aiResponseText = response.content;
      } else {
        aiResponseText = 'AI ƒë√£ ph·∫£n h·ªìi nh∆∞ng kh√¥ng th·ªÉ hi·ªÉn th·ªã n·ªôi dung.';
      }
      
      // Send analysis result as message
      if (onSendMessage) {
        onSendMessage(analysisPrompt, aiResponseText, imageData);
      }
      
    } catch (error) {
      console.error('L·ªói ph√¢n t√≠ch ·∫£nh:', error);
      
      // Try fallback with different approach
      try {
        console.log('Trying fallback analysis...');
        const fallbackResponse = await window.puter.ai.chat(
          `Ph√¢n t√≠ch ·∫£nh: ${imageData.name}. ${prompt}. 
          
          L∆∞u √Ω: Kh√¥ng th·ªÉ t·∫£i ·∫£nh tr·ª±c ti·∫øp, vui l√≤ng m√¥ t·∫£ n·ªôi dung ·∫£nh n√†y d·ª±a tr√™n t√™n file ho·∫∑c th·ª≠ upload ·∫£nh kh√°c v·ªõi ƒë·ªãnh d·∫°ng JPG/PNG.`, {
          model: selectedModel
        });
        
        if (onSendMessage) {
          onSendMessage(
            `Ph√¢n t√≠ch ·∫£nh: ${imageData.name}`, 
            `‚ö†Ô∏è Kh√¥ng th·ªÉ ph√¢n t√≠ch ·∫£nh tr·ª±c ti·∫øp.\n\n${fallbackResponse}`, 
            imageData
          );
        }
      } catch (fallbackError) {
        if (onSendMessage) {
          onSendMessage(
            `Ph√¢n t√≠ch ·∫£nh: ${imageData.name}`, 
            `‚ùå L·ªói ph√¢n t√≠ch ·∫£nh: ${error.message}\n\nüí° Th·ª≠:\n- S·ª≠ d·ª•ng ·∫£nh ƒë·ªãnh d·∫°ng JPG/PNG\n- Ch·ªçn model kh√°c (GPT-4o, Claude Vision)\n- Upload ·∫£nh k√≠ch th∆∞·ªõc nh·ªè h∆°n`, 
            imageData
          );
        }
      }
    } finally {
      setIsAnalyzing(false);
    }
  };

  const extractText = async (imageData) => {
    setIsAnalyzing(true);
    
    try {
      console.log('Extracting text using img2txt...'); // Debug
      
      // Use base64 for OCR
      const extractedText = await window.puter.ai.img2txt(imageData.base64);
      
      const ocrResult = extractedText || 'Kh√¥ng t√¨m th·∫•y text trong ·∫£nh';
      const prompt = `Tr√≠ch xu·∫•t text t·ª´ ·∫£nh: ${imageData.name}`;
      
      if (onSendMessage) {
        onSendMessage(prompt, `**Text ƒë∆∞·ª£c tr√≠ch xu·∫•t:**\n\n${ocrResult}`, imageData);
      }
      
    } catch (error) {
      console.error('L·ªói OCR:', error);
      
      // Fallback: use vision model for text extraction
      try {
        console.log('OCR failed, using vision model...');
        const response = await window.puter.ai.chat(
          "Tr√≠ch xu·∫•t t·∫•t c·∫£ text c√≥ trong ·∫£nh n√†y. Ch·ªâ tr·∫£ v·ªÅ text ƒë∆∞·ª£c t√¨m th·∫•y, kh√¥ng th√™m gi·∫£i th√≠ch g√¨ kh√°c.", 
          imageData.base64, 
          { model: selectedModel }
        );
        
        // Process vision response
        let extractedText = '';
        if (typeof response === 'string') {
          extractedText = response;
        } else if (response && response.message && response.message.content) {
          extractedText = Array.isArray(response.message.content) 
            ? response.message.content[0]?.text || response.message.content[0]
            : response.message.content;
        } else {
          extractedText = 'Kh√¥ng th·ªÉ tr√≠ch xu·∫•t text b·∫±ng vision model';
        }
        
        if (onSendMessage) {
          onSendMessage(
            `OCR ·∫£nh: ${imageData.name}`, 
            `**Text ƒë∆∞·ª£c tr√≠ch xu·∫•t (via Vision):**\n\n${extractedText}`, 
            imageData
          );
        }
        
      } catch (fallbackError) {
        if (onSendMessage) {
          onSendMessage(
            `OCR ·∫£nh: ${imageData.name}`, 
            `‚ùå L·ªói tr√≠ch xu·∫•t text: ${error.message}\n\nüí° Th·ª≠:\n- ·∫¢nh c√≥ text r√µ r√†ng h∆°n\n- ƒê·ªãnh d·∫°ng JPG/PNG\n- Model kh√°c c√≥ vision capability`, 
            imageData
          );
        }
      }
    } finally {
      setIsAnalyzing(false);
    }
  };

  const removeImage = (imageId) => {
    setUploadedImages(prev => {
      const filtered = prev.filter(img => img.id !== imageId);
      // Cleanup preview URLs
      const removed = prev.find(img => img.id === imageId);
      if (removed?.previewUrl) {
        URL.revokeObjectURL(removed.previewUrl);
      }
      return filtered;
    });
  };

  const downloadImage = async (imageData) => {
    try {
      const link = document.createElement('a');
      link.href = imageData.previewUrl;
      link.download = imageData.name;
      link.click();
    } catch (error) {
      console.error('L·ªói download:', error);
    }
  };

  const formatFileSize = (bytes) => {
    if (bytes === 0) return '0 Bytes';
    const k = 1024;
    const sizes = ['Bytes', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
  };

  return (
    <div className="space-y-4">
      {/* Upload Area */}
      <div
        className={`border-2 border-dashed rounded-lg p-6 text-center transition duration-200 ${
          dragActive 
            ? 'border-blue-500 bg-blue-50' 
            : 'border-gray-300 hover:border-gray-400'
        }`}
        onDragEnter={handleDrag}
        onDragLeave={handleDrag}
        onDragOver={handleDrag}
        onDrop={handleDrop}
      >
        <input
          ref={fileInputRef}
          type="file"
          multiple
          accept="image/*"
          onChange={handleFileSelect}
          className="hidden"
        />
        
        <div className="space-y-3">
          <div className="flex justify-center">
            {isUploading ? (
              <Loader2 className="h-10 w-10 text-blue-500 animate-spin" />
            ) : (
              <Upload className="h-10 w-10 text-gray-400" />
            )}
          </div>
          
          <div>
            <p className="text-gray-600 font-medium">
              {isUploading ? 'ƒêang upload...' : 'Upload ·∫£nh ƒë·ªÉ ph√¢n t√≠ch'}
            </p>
            <p className="text-sm text-gray-500 mt-1">
              K√©o th·∫£ ·∫£nh v√†o ƒë√¢y ho·∫∑c click ƒë·ªÉ ch·ªçn file
            </p>
            <p className="text-xs text-gray-400 mt-2">
              H·ªó tr·ª£: JPG, PNG, GIF, WebP ‚Ä¢ T·ªëi ƒëa 30MB
            </p>
          </div>
          
          <button
            onClick={() => fileInputRef.current?.click()}
            disabled={isUploading}
            className="bg-blue-500 text-white px-4 py-2 rounded-lg hover:bg-blue-600 disabled:opacity-50 transition duration-200"
          >
            Ch·ªçn ·∫£nh
          </button>
        </div>
      </div>

      {/* Uploaded Images */}
      {uploadedImages.length > 0 && (
        <div className="space-y-3">
          <h3 className="font-semibold text-gray-800">·∫¢nh ƒë√£ upload ({uploadedImages.length})</h3>
          
          <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
            {uploadedImages.map((image) => (
              <div key={image.id} className="border rounded-lg overflow-hidden bg-white shadow-sm">
                {/* Image Preview */}
                <div className="relative">
                  <img
                    src={image.previewUrl}
                    alt={image.name}
                    className="w-full h-48 object-cover"
                  />
                  <button
                    onClick={() => removeImage(image.id)}
                    className="absolute top-2 right-2 bg-red-500 text-white p-1 rounded-full hover:bg-red-600 transition duration-200"
                  >
                    <Trash2 className="h-4 w-4" />
                  </button>
                </div>
                
                {/* Image Info */}
                <div className="p-4">
                  <h4 className="font-medium text-gray-800 truncate">{image.name}</h4>
                  <p className="text-sm text-gray-500">
                    {formatFileSize(image.size)} ‚Ä¢ {new Date(image.uploadedAt).toLocaleString('vi-VN')}
                  </p>
                  
                  {/* Action Buttons */}
                  <div className="flex space-x-2 mt-3">
                    <button
                      onClick={() => analyzeImage(image)}
                      disabled={isAnalyzing}
                      className="flex items-center space-x-1 bg-purple-500 text-white px-3 py-1.5 rounded text-sm hover:bg-purple-600 disabled:opacity-50 transition duration-200"
                    >
                      {isAnalyzing ? (
                        <Loader2 className="h-4 w-4 animate-spin" />
                      ) : (
                        <Eye className="h-4 w-4" />
                      )}
                      <span>Ph√¢n t√≠ch</span>
                    </button>
                    
                    <button
                      onClick={() => extractText(image)}
                      disabled={isAnalyzing}
                      className="flex items-center space-x-1 bg-green-500 text-white px-3 py-1.5 rounded text-sm hover:bg-green-600 disabled:opacity-50 transition duration-200"
                    >
                      <FileText className="h-4 w-4" />
                      <span>OCR</span>
                    </button>
                    
                    <button
                      onClick={() => downloadImage(image)}
                      className="flex items-center space-x-1 bg-gray-500 text-white px-3 py-1.5 rounded text-sm hover:bg-gray-600 transition duration-200"
                    >
                      <Download className="h-4 w-4" />
                    </button>
                  </div>
                </div>
              </div>
            ))}
          </div>
        </div>
      )}

      {/* Quick Actions */}
      {uploadedImages.length > 0 && (
        <div className="bg-gray-50 p-4 rounded-lg">
          <h4 className="font-medium text-gray-800 mb-3">Ph√¢n t√≠ch nhanh</h4>
          <div className="grid grid-cols-2 md:grid-cols-4 gap-2">
            {[
              { label: 'M√¥ t·∫£ chi ti·∫øt', prompt: 'H√£y m√¥ t·∫£ r·∫•t chi ti·∫øt nh·ªØng g√¨ b·∫°n th·∫•y trong ·∫£nh n√†y, bao g·ªìm m√†u s·∫Øc, ƒë·ªëi t∆∞·ª£ng, b·ªëi c·∫£nh v√† c·∫£m x√∫c' },
              { label: 'Tr√≠ch xu·∫•t text', action: 'ocr' },
              { label: 'Ph√¢n t√≠ch bi·ªÉu ƒë·ªì', prompt: 'Ph√¢n t√≠ch bi·ªÉu ƒë·ªì/chart trong ·∫£nh n√†y v√† gi·∫£i th√≠ch √Ω nghƒ©a c·ªßa d·ªØ li·ªáu' },
              { label: 'T√¨m l·ªói code', prompt: 'Ki·ªÉm tra code trong ·∫£nh n√†y v√† t√¨m ra c√°c l·ªói ho·∫∑c c·∫£i ti·∫øn c√≥ th·ªÉ' }
            ].map((action, index) => (
              <button
                key={index}
                onClick={() => {
                  const lastImage = uploadedImages[uploadedImages.length - 1];
                  if (action.action === 'ocr') {
                    extractText(lastImage);
                  } else {
                    analyzeImage(lastImage, action.prompt);
                  }
                }}
                disabled={isAnalyzing || uploadedImages.length === 0}
                className="bg-white border border-gray-200 text-gray-700 px-3 py-2 rounded text-sm hover:bg-gray-50 disabled:opacity-50 transition duration-200"
              >
                {action.label}
              </button>
            ))}
          </div>
        </div>
      )}
    </div>
  );
};

export default ImageUploadComponent;